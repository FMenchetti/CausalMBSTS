############################################################################
####                                                                    ####
####                        MIXED FUNCTIONS                             ####
####                                                                    ####
############################################################################


############################################################################
### Function to create weekdays dummy & holiday dummies
############################################################################

# Starting from a vector of dates, the following function returns a matrix 
# where each column is a day-of-the-week dummy

day.dummy<-function(dates){
  
  # check
  if(class(dates) != "Date"){print(paste("warning: dates must be a 'Date' object"))}
  
  # Matrix 
  weekday<-weekdays(dates)
  week<-matrix(0,length(dates),7)
  colnames(week)<-unique(weekday)
  
  for(i in 1:ncol(week)){
    for(j in 1:length(weekday)){
      if(weekday[j] == colnames(week)[i]){
        week[j,i]<-1
      }
    }
  }
  return(week)
}

# Starting from a vector of dates, the following function returns a dummy that takes value 1
# every time a holiday is encountered (default is Italian holidays)

hol.dummy<-function(dates, add = T, lags=c(0,0)){
  
  year<-unique(as.numeric(format(as.Date(dates, format="%Y-%m-%d"),"%Y")))
  ITRepublicAnniversary<-as.Date(gsub("$","-06-02",year),format="%Y-%m-%d")
  holidays<- c(ITRepublicAnniversary,
               as.Date(holiday(year[1]:year[length(year)], Holiday= listHolidays("IT")[1]), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= listHolidays("IT")[2]), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= listHolidays("IT")[3]), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= listHolidays("IT")[4]), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= listHolidays("IT")[5]), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= "NewYearsDay"), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= "Easter"), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= "EasterMonday"), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= "LaborDay"), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= "ChristmasDay"), format="%Y-%m-%d"),
               as.Date(holiday(year[1]:year[length(year)], Holiday= "BoxingDay"), format="%Y-%m-%d"))

  if(add==T){
    interval<-seq(from=dates[1], to=dates[length(dates)], by = 1)
    x<-rep(0,length(interval))
    x[which(interval %in% holidays)-lags[1]]<-1
    x[which(interval %in% holidays)+lags[2]]<-1
    if(lags[1]>0) {x[interval %in% holidays]<-0}
  } else {
    x<-rep(0,length(dates))
    x[which(dates %in% holidays)-lags[1]]<-1
    x[which(dates %in% holidays)+lags[2]]<-1
    if(lags[2]>0) {x[dates %in% holidays]<-0}
  } 
  return(x)
}


############################################################################
### Unpack Coop data 
############################################################################

# Data must be provided with the following colnames: "Categoria", "Sottocategoria"
# "Segmento", "Cod.Magazzino.Articolo", "EAN" , "Articolo" , "Posizionamento.Mercato",
# "Data", "PEZZI" , "VOLUME", "VENDUTO", "VENDUTO.PROMO"

coop.unpack<-function(data.raw){
  
  # check format
  if(colnames(data.raw) != c("Categoria", "Sottocategoria",
                        "Segmento", "Cod.Magazzino.Articolo", "EAN" , "Articolo" , "Posizionamento.Mercato",
                        "Data", "PEZZI" , "VOLUME", "VENDUTO", "VENDUTO.PROMO")) { 
     print(paste(" Data provided is not in the required format, check column names or column order")) }
  
  # check presence of negative data (if so, replace with NAs)
  
  for(i in 9:12){
    
    if(sum(data.raw[,i]<0, na.rm=T)>0){
       ind<-which(data.raw[,i]<0)
       data.raw[ind,i]<-NA
    }
  }
  
  # summing up sales of the same product appearing in the same day
  
  # data.raw<-aggregate(data.raw$PEZZI, by = list(data.raw$Cod.Magazzino.Articolo, data.raw$Data), sum, na.rm=T)
  # 
  # write.table(data.raw, "prova.csv", col.names = T)
  # 
  # stop()
  
  # formatting
  data.raw$Data<-as.Date(data.raw$Data, format="%d/%m/%Y")
  for (i in 9:12) data.raw[,i]<-as.numeric(gsub(",","",data.raw[,i]))
    
  # adding a "price" column
  prezzo<-round(data.raw$VENDUTO / data.raw$PEZZI, digits =2)
  data.raw<-data.frame(data.raw, prezzo)
  
  # reshaping
  dat<-data.frame(articolo = data.raw$Cod.Magazzino.Articolo, date = as.Date(data.raw$Data, 
                                                                             format = "%d/%m/%Y"), 
                  pezzi = data.raw$PEZZI, volume = data.raw$VOLUME, venduto = data.raw$VENDUTO, 
                  vendpromo = data.raw$VENDUTO.PROMO, prezzo = data.raw$prezzo)
  tdata<-reshape(dat, direction = "wide", idvar = "date", timevar = "articolo")
  tdata<-tdata[order(tdata$date),]
  
    # sanity check
  tot.days<-nrow(tdata)
  calendar.days<-max(tdata$date)-min(tdata$date)+1
  
  if(calendar.days != tot.days){ 
    
    # we need to add back the missing holidays because the data will probably exhibit a seasonal pattern
    # to add back holidays, use timeDate package and the previously defined "hol" function
    
    interval<-seq(tdata$date[1],tdata$date[length(tdata$date)],1)
    hol<-as.logical(hol.dummy(interval,add=F, lag=c(0,0)))
    holidays<-interval[hol]
    
    # If the dates vector doesn't contain the holiday, add it with NAs and order the dates 
    # If it does, replace the data with NAs (during holidays, few stores stay open and those data would be outliers)
    
    hol<-tdata$date[tdata$date %in% holidays]  # selecting holidays already present in the dataset
    new<-matrix(NA,length(hol),ncol(tdata)-1)  
    new<-data.frame(hol, new)
    colnames(new)<-colnames(tdata)             
    tdata[tdata$date %in% holidays,]<- new    # substituting sales data during holidays with NAs
        
    hol<-holidays[-which(holidays %in% hol)]  # selecting missing holidays
    new<-matrix(NA,length(hol),ncol(tdata)-1)
    new<-data.frame(hol, new)
    colnames(new)<-colnames(tdata)
    tdata<-rbind(tdata, new)                  # adding back missing holidays

    
  }
tdata<-tdata[order(tdata$date),]  
tdata$date<-as.Date(tdata$date, format="%Y-%m-%d")
print(paste("Total number of items: ", length(unique(data.raw$Cod.Magazzino.Articolo))))
print(paste("Number of holidays added to the dataset: ", length(hol)))
return(tdata)
}

############################################################################
### Variance and volatility proxies
############################################################################

# Unbiased variance proxies/biased volatility proxies

simple<-function(close, open){(log(close)-log(open))^2}
park<-function(high,low){(1/(4*log(2)))*(log(high)-log(low))^2}
GK<-function(high,low,open,close){0.5*(log(high)-log(low))^2 - 
    (2*log(2)-1)*(log(close)-log(open))^2}

# Unbiased volatility proxies

u.simple<-function(close, open){abs(log(close)-log(open))*sqrt(pi/2)}
u.park<-function(high,low){(sqrt(pi/8))*(log(high)-log(low))}
u.GK<-function(high,low,open,close){sqrt(GK(high,low,open,close))*1.034}


############################################################################
### Missing data imputation 
############################################################################

# This function performes imputation of missing values by the average of the two periods
# preceeding the missing (suitable for seasonal models) 

na.mean<-function(x,period){
  
  if(anyNA(x) == T) {
    
  ind<-which(is.na(x))
  
  for(i in 1:length(ind)){
    if(ind[i]-2*period>0) {
      x[ind][i]<-round(mean(c(x[ind[i]-period],x[ind[i]-2*period])),digits=2)
    } else { # when the missing is at the beginning, impute the average of the next periods
      select<-seq(1,length(x),period)
      x[ind][i]<-round(mean(x[seq(ind[i],12*period,period)], na.rm=T),digits = 2) 
    }
   }
  }
  
  x<-x
  
  # check
  if(sum(is.nan(x)) == 0) { return(x)} else { 
    
    ind<-which(is.nan(x))
    
    for(i in 1:length(ind)){
      if(ind[i]-2*period>0) {
        x[ind][i]<-round(mean(c(x[ind[i]-period],x[ind[i]-3*period])),digits=T)
      } else { # when the missing is at the beginning, impute the average of the next periods
        select<-seq(1,length(x),period)
        x[ind][i]<-round(mean(x[seq(ind[i],60*period,period)], na.rm=T),digits=T) 
      }
    }
  }
  x<-x
}

# This function imputes missing values by their smoothed estimates as 
# computed on the basis of a seasonal SSM for daily data 

na.kalman<-function(y, period = 0 , xreg = NULL , P1){
  
  if(period == 0 & is.null(xreg) == F){
    
    updatefn<-function(pars, model) {
      model["H"] <- exp(pars[1])
      model["Q", etas = "level"] <- exp(pars[2])
      model
    }
    
    m<-SSModel(log(y) ~  SSMtrend(degree = 1, Q = matrix(NA), P1 = P1) + 
                                  SSMregression(~ xreg, P1 = diag(P1,NCOL(xreg))) , H = matrix(NA))
  
    } else if (period != 0 & is.null(xreg) == F) { 
    
    updatefn<-function(pars, model) {
      model["H"] <- exp(pars[1])
      model["Q", etas = "level"] <- exp(pars[2])
      model["Q", etas = "seasonal"] <- exp(pars[3])
      model
    }
    
    m<-SSModel(log(y) ~  SSMtrend(degree = 1, Q = matrix(NA), P1 = P1) + 
                                  SSMseasonal(period = period, sea.type = "dummy", Q = matrix(NA), P1 = diag(P1, period-1)) +
                                  SSMregression(~ xreg, P1 = diag(P1,NCOL(xreg))), H = matrix(NA))
  
  } else if (period == 0 & is.null(xreg) == T) { 
    
    updatefn<-function(pars, model) {
      model["H"] <- exp(pars[1])
      model["Q", etas = "level"] <- exp(pars[2])
      model
    }
    
    m<-SSModel(log(y) ~  SSMtrend(degree = 1, Q = matrix(NA), P1 = P1) , H = matrix(NA))
    
  } else if (period != 0 & is.null(xreg) == T) {
    
    updatefn<-function(pars, model) {
      model["H"] <- exp(pars[1])
      model["Q", etas = "level"] <- exp(pars[2])
      model["Q", etas = "seasonal"] <- exp(pars[3])
      model
    }
    
    m<-SSModel(log(y) ~  SSMtrend(degree = 1, Q = matrix(NA), P1 = P1) + 
                 SSMseasonal(period = period, sea.type = "dummy", Q = matrix(NA), P1 = diag(P1,period-1)) , H = matrix(NA))
    
  }
  
  npar<-sum(is.na(m$H))+sum(is.na(m$Q))+sum(is.na(m$T))
  model<-fitSSM(model = m, inits = rep(log(var(y, na.rm=T)), times=npar), 
                  updatefn = updatefn, 
                  method="BFGS")
                  #maxit=1000) 
  
  out<- KFS(model$model, filtering = c("state", "mean", "disturbance"), smoothing = c("state", "mean", "disturbance"))
  
  ind<-which(is.na(y))
  y[ind]<-exp(out$muhat[ind])
  return(y)
}

############################################################################
### Data aggregation 
############################################################################

aggregating<-function(dataset,price){
  
  y.mean<-apply(dataset,1,mean, na.rm=T) 
  y.sum<-rowSums(dataset)
  y.mean.price<-c()
  for(i in 1:nrow(price)){
    y.mean.price[i]<-weighted.mean(x=price[i,],w=dataset[i,], na.rm = T)
  }
  
  aggr<-data.frame(y.mean,y.sum,y.mean.price)
  return(aggr)
}

############################################################################
### Functions from CausalImpact to get samples from pred. post. distribution
############################################################################

library(assertthat)

GetPosteriorStateSamples <- function(bsts.model) {
  # Returns a matrix of simulated values from the marginal posterior
  # distribution for the sum of all state variables.
  #
  # Args:
  #   bsts.model: A fitted model returned by \code{bsts()}.
  #
  # Returns:
  #   matrix [number of post-burn-in MCMC samples] x [time points]
  
  # Get state contributions (e.g., 1000 samples x 2 states x 365 time pts),
  # discarding burn-in samples (=> 900 x 2 x 365)
  burn <- SuggestBurn(0.1, bsts.model)
  assert_that(burn > 0)
  state.contributions <- bsts.model$state.contributions[-seq_len(burn), , ,
                                                        drop = FALSE]
  
  # Sum across states, call it 'state.samples' (=> 900 x 365)
  state.samples <- rowSums(aperm(state.contributions, c(1, 3, 2)), dims = 2)
  return(state.samples)
}

ComputeResponseTrajectories <- function(bsts.model) {
  # Generates trajectories of the response variable. A trajectory is a simulated
  # time series drawn from the posterior predictive distribution over the data.
  # This function differs from GetPosteriorStateSamples(). The latter returns
  # the posterior mean of the response. This function returns the actual value
  # (posterior mean + observation noise).
  #
  # Args:
  #   bsts.model: A model object as returned by \code{bsts()}.
  #
  # Returns:
  #   matrix [number of post-burn-in MCMC samples] x [time points]
  
  # Get posterior state samples
  state.samples <- GetPosteriorStateSamples(bsts.model)
  
  # Get observation noise standard deviation samples
  burn <- SuggestBurn(0.1, bsts.model)
  assert_that(burn > 0)
  sigma.obs <- bsts.model$sigma.obs[-seq_len(burn)]  # e.g., 900
  
  # Sample from the posterior predictive density over data
  n.samples <- dim(state.samples)[1]  # e.g., 900 x 365
  obs.noise.samples <- matrix(rnorm(prod(dim(state.samples)), 0, sigma.obs),
                              nrow = n.samples)
  y.samples <- state.samples + obs.noise.samples
  return(y.samples)
}

